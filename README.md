# Kennesaw-State-University-REU
This is a project from a Research Experience for Undergraduates (REU) with Kennesaw State University. Under Drs. Selena He and Shirley Tian with the mentor ship of Dr. Honghui Xu. The project aims to improve emotion detection in sensor driven AI using a hybrid CNN-LSTM model.

Abstract: This project explores the development of an emotion recognition system that utilizes sensor-driven artificial intelligence (AI) to analyze audio data. Further addressing challenges such as environmental noise, speaker variability, and contextual cues for emotion expression. This project will utilize low-cost microphone sensors and deep learning models, as well as the capturing of temporal speech patterns and contextual dependencies. The methodology includes training on controlled datasets and evaluation on speech, with a focus on enabling generalization across diverse speakers and environments. In regards to AI use, this work will contribute to the development of real-time emotion recognition systems grounded in sensor-based AI. Overall, this project will help in advancing applications used in mental health monitoring, humanâ€“device interactions, and personalized assistance use. 

Project Statement: This project's goal is to train a sensor-driven AI model to correctly detect and categorize emotions from the CREMA-D Dataset. The emotions in this dataset are sadness, anger, disgust, fear, happy, and neutral. This project will utilize a Long Short-Term Memory (LSTM) AI. This is a special kind of Recurrent Neural Network (RNN). It is very good at understanding sequences of data over time, i.e., speech, audio, or music. LSTM is very good at remembering information from early on in the sequence, especially compared to other neural networks. We want to use LSTM because tone and pitch are some of the features used in emotion detection, and they will change throughout the sequence.
